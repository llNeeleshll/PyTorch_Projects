{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Example with BCELoss function -> For Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.optim \n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the dataset first\n",
    "df = pd.read_csv(r'C:\\Users\\neele\\OneDrive\\Documents\\Git Repositories\\PyTorch_Projects\\Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,3:13].values\n",
    "y = df.iloc[:,13].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = (ct.fit_transform(X))\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "0     1.001501 -0.579467 -0.576388  0.356500  0.913248 -0.655786  0.345680   \n",
      "1    -0.998501  1.725723 -0.576388 -0.203898  0.913248  0.294938 -0.348369   \n",
      "2    -0.998501 -0.579467  1.734942 -0.961472  0.913248 -1.416365 -0.695393   \n",
      "3     1.001501 -0.579467 -0.576388 -0.940717 -1.094993 -1.131148  1.386753   \n",
      "4     1.001501 -0.579467 -0.576388 -1.397337  0.913248  1.625953  1.386753   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "7995  1.001501 -0.579467 -0.576388  1.207474  0.913248  1.435808  1.039728   \n",
      "7996  1.001501 -0.579467 -0.576388  0.314989 -1.094993  1.816097 -1.389442   \n",
      "7997  1.001501 -0.579467 -0.576388  0.865009 -1.094993 -0.085351 -1.389442   \n",
      "7998  1.001501 -0.579467 -0.576388  0.159323  0.913248  0.390011  1.039728   \n",
      "7999 -0.998501  1.725723 -0.576388  0.470655  0.913248  1.150590 -1.389442   \n",
      "\n",
      "            7         8         9         10        11  \n",
      "0    -1.218471  0.808436  0.649203  0.974817  1.367670  \n",
      "1     0.696838  0.808436  0.649203  0.974817  1.661254  \n",
      "2     0.618629 -0.916688  0.649203 -1.025834 -0.252807  \n",
      "3     0.953212 -0.916688  0.649203 -1.025834  0.915393  \n",
      "4     1.057449 -0.916688 -1.540351 -1.025834 -1.059600  \n",
      "...        ...       ...       ...       ...       ...  \n",
      "7995 -0.102301 -0.916688  0.649203  0.974817 -0.539860  \n",
      "7996 -1.218471 -0.916688  0.649203  0.974817 -1.733882  \n",
      "7997 -1.218471  2.533560 -1.540351 -1.025834 -0.142765  \n",
      "7998  1.827259 -0.916688  0.649203 -1.025834 -0.050826  \n",
      "7999  1.149720 -0.916688  0.649203  0.974817 -0.814568  \n",
      "\n",
      "[8000 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(pd.DataFrame(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dimension, output_dimension):\n",
    "        super(ANN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dimension, 64),\n",
    "            nn.Sigmoid(),            \n",
    "            nn.Linear(64,64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64,32),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(32,32),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(32,output_dimension),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output neuron would be 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=64, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (6): Sigmoid()\n",
      "    (7): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (8): Sigmoid()\n",
      "    (9): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ANN(12,1).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the optimizer is <strong>Adam</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to tensors for nupmy Array\n",
    "X_train=torch.FloatTensor(X_train).to(device)\n",
    "X_test=torch.FloatTensor(X_test).to(device)\n",
    "y_train=torch.LongTensor(y_train).to(device)\n",
    "y_test=torch.LongTensor(y_test).to(device)\n",
    "\n",
    "# Make torch datasets from train and test sets\n",
    "train = torch.utils.data.TensorDataset(X_train,y_train)\n",
    "test = torch.utils.data.TensorDataset(X_test,y_test)\n",
    "\n",
    "# Create train and test data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 64, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the predictions are calculated\n",
    "\n",
    "<strong>preds = torch.round(output).to(int).squeeze(1)</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with the training...\n",
      "epoch : 1\n",
      "training loss: 0.0075, acc 0.7945 \n",
      "validation loss: 0.0068, validation acc 0.8035 \n",
      "epoch : 2\n",
      "training loss: 0.0069, acc 0.7920 \n",
      "validation loss: 0.0066, validation acc 0.8010 \n",
      "epoch : 3\n",
      "training loss: 0.0068, acc 0.7928 \n",
      "validation loss: 0.0067, validation acc 0.8005 \n",
      "epoch : 4\n",
      "training loss: 0.0067, acc 0.8096 \n",
      "validation loss: 0.0066, validation acc 0.8250 \n",
      "epoch : 5\n",
      "training loss: 0.0065, acc 0.8285 \n",
      "validation loss: 0.0065, validation acc 0.8290 \n",
      "epoch : 6\n",
      "training loss: 0.0064, acc 0.8289 \n",
      "validation loss: 0.0063, validation acc 0.8385 \n",
      "epoch : 7\n",
      "training loss: 0.0064, acc 0.8326 \n",
      "validation loss: 0.0063, validation acc 0.8345 \n",
      "epoch : 8\n",
      "training loss: 0.0063, acc 0.8345 \n",
      "validation loss: 0.0064, validation acc 0.8400 \n",
      "epoch : 9\n",
      "training loss: 0.0063, acc 0.8351 \n",
      "validation loss: 0.0062, validation acc 0.8370 \n",
      "epoch : 10\n",
      "training loss: 0.0060, acc 0.8415 \n",
      "validation loss: 0.0060, validation acc 0.8485 \n",
      "epoch : 11\n",
      "training loss: 0.0058, acc 0.8464 \n",
      "validation loss: 0.0058, validation acc 0.8520 \n",
      "epoch : 12\n",
      "training loss: 0.0056, acc 0.8506 \n",
      "validation loss: 0.0056, validation acc 0.8600 \n",
      "epoch : 13\n",
      "training loss: 0.0055, acc 0.8530 \n",
      "validation loss: 0.0056, validation acc 0.8520 \n",
      "epoch : 14\n",
      "training loss: 0.0055, acc 0.8574 \n",
      "validation loss: 0.0056, validation acc 0.8575 \n",
      "epoch : 15\n",
      "training loss: 0.0054, acc 0.8564 \n",
      "validation loss: 0.0055, validation acc 0.8620 \n",
      "epoch : 16\n",
      "training loss: 0.0053, acc 0.8601 \n",
      "validation loss: 0.0055, validation acc 0.8585 \n",
      "epoch : 17\n",
      "training loss: 0.0053, acc 0.8594 \n",
      "validation loss: 0.0056, validation acc 0.8575 \n",
      "epoch : 18\n",
      "training loss: 0.0053, acc 0.8614 \n",
      "validation loss: 0.0054, validation acc 0.8595 \n",
      "epoch : 19\n",
      "training loss: 0.0053, acc 0.8640 \n",
      "validation loss: 0.0057, validation acc 0.8605 \n",
      "epoch : 20\n",
      "training loss: 0.0053, acc 0.8612 \n",
      "validation loss: 0.0054, validation acc 0.8615 \n",
      "epoch : 21\n",
      "training loss: 0.0052, acc 0.8649 \n",
      "validation loss: 0.0055, validation acc 0.8640 \n",
      "epoch : 22\n",
      "training loss: 0.0052, acc 0.8636 \n",
      "validation loss: 0.0056, validation acc 0.8590 \n",
      "epoch : 23\n",
      "training loss: 0.0052, acc 0.8670 \n",
      "validation loss: 0.0056, validation acc 0.8565 \n",
      "epoch : 24\n",
      "training loss: 0.0051, acc 0.8656 \n",
      "validation loss: 0.0054, validation acc 0.8610 \n",
      "epoch : 25\n",
      "training loss: 0.0051, acc 0.8659 \n",
      "validation loss: 0.0055, validation acc 0.8580 \n",
      "epoch : 26\n",
      "training loss: 0.0051, acc 0.8665 \n",
      "validation loss: 0.0058, validation acc 0.8620 \n",
      "epoch : 27\n",
      "training loss: 0.0051, acc 0.8646 \n",
      "validation loss: 0.0056, validation acc 0.8520 \n",
      "epoch : 28\n",
      "training loss: 0.0051, acc 0.8649 \n",
      "validation loss: 0.0055, validation acc 0.8650 \n",
      "epoch : 29\n",
      "training loss: 0.0051, acc 0.8666 \n",
      "validation loss: 0.0055, validation acc 0.8560 \n",
      "epoch : 30\n",
      "training loss: 0.0050, acc 0.8662 \n",
      "validation loss: 0.0056, validation acc 0.8620 \n",
      "epoch : 31\n",
      "training loss: 0.0051, acc 0.8680 \n",
      "validation loss: 0.0055, validation acc 0.8635 \n",
      "epoch : 32\n",
      "training loss: 0.0050, acc 0.8680 \n",
      "validation loss: 0.0054, validation acc 0.8625 \n",
      "epoch : 33\n",
      "training loss: 0.0050, acc 0.8679 \n",
      "validation loss: 0.0054, validation acc 0.8680 \n",
      "epoch : 34\n",
      "training loss: 0.0050, acc 0.8684 \n",
      "validation loss: 0.0057, validation acc 0.8635 \n",
      "epoch : 35\n",
      "training loss: 0.0050, acc 0.8696 \n",
      "validation loss: 0.0055, validation acc 0.8615 \n",
      "epoch : 36\n",
      "training loss: 0.0050, acc 0.8696 \n",
      "validation loss: 0.0056, validation acc 0.8615 \n",
      "epoch : 37\n",
      "training loss: 0.0049, acc 0.8724 \n",
      "validation loss: 0.0056, validation acc 0.8585 \n",
      "epoch : 38\n",
      "training loss: 0.0049, acc 0.8712 \n",
      "validation loss: 0.0057, validation acc 0.8555 \n",
      "epoch : 39\n",
      "training loss: 0.0049, acc 0.8750 \n",
      "validation loss: 0.0056, validation acc 0.8580 \n",
      "epoch : 40\n",
      "training loss: 0.0049, acc 0.8735 \n",
      "validation loss: 0.0056, validation acc 0.8635 \n",
      "epoch : 41\n",
      "training loss: 0.0048, acc 0.8735 \n",
      "validation loss: 0.0055, validation acc 0.8590 \n",
      "epoch : 42\n",
      "training loss: 0.0048, acc 0.8730 \n",
      "validation loss: 0.0056, validation acc 0.8595 \n",
      "epoch : 43\n",
      "training loss: 0.0048, acc 0.8734 \n",
      "validation loss: 0.0058, validation acc 0.8570 \n",
      "epoch : 44\n",
      "training loss: 0.0048, acc 0.8725 \n",
      "validation loss: 0.0058, validation acc 0.8575 \n",
      "epoch : 45\n",
      "training loss: 0.0048, acc 0.8763 \n",
      "validation loss: 0.0058, validation acc 0.8600 \n",
      "epoch : 46\n",
      "training loss: 0.0047, acc 0.8775 \n",
      "validation loss: 0.0059, validation acc 0.8600 \n",
      "epoch : 47\n",
      "training loss: 0.0047, acc 0.8769 \n",
      "validation loss: 0.0056, validation acc 0.8625 \n",
      "epoch : 48\n",
      "training loss: 0.0047, acc 0.8742 \n",
      "validation loss: 0.0059, validation acc 0.8570 \n",
      "epoch : 49\n",
      "training loss: 0.0048, acc 0.8714 \n",
      "validation loss: 0.0056, validation acc 0.8620 \n",
      "epoch : 50\n",
      "training loss: 0.0047, acc 0.8760 \n",
      "validation loss: 0.0057, validation acc 0.8595 \n",
      "epoch : 51\n",
      "training loss: 0.0046, acc 0.8775 \n",
      "validation loss: 0.0057, validation acc 0.8600 \n",
      "epoch : 52\n",
      "training loss: 0.0046, acc 0.8792 \n",
      "validation loss: 0.0061, validation acc 0.8520 \n",
      "epoch : 53\n",
      "training loss: 0.0046, acc 0.8794 \n",
      "validation loss: 0.0057, validation acc 0.8580 \n",
      "epoch : 54\n",
      "training loss: 0.0046, acc 0.8808 \n",
      "validation loss: 0.0058, validation acc 0.8520 \n",
      "epoch : 55\n",
      "training loss: 0.0046, acc 0.8805 \n",
      "validation loss: 0.0059, validation acc 0.8625 \n",
      "epoch : 56\n",
      "training loss: 0.0046, acc 0.8800 \n",
      "validation loss: 0.0058, validation acc 0.8565 \n",
      "epoch : 57\n",
      "training loss: 0.0046, acc 0.8805 \n",
      "validation loss: 0.0061, validation acc 0.8540 \n",
      "epoch : 58\n",
      "training loss: 0.0045, acc 0.8831 \n",
      "validation loss: 0.0058, validation acc 0.8565 \n",
      "epoch : 59\n",
      "training loss: 0.0045, acc 0.8806 \n",
      "validation loss: 0.0058, validation acc 0.8600 \n",
      "epoch : 60\n",
      "training loss: 0.0045, acc 0.8840 \n",
      "validation loss: 0.0061, validation acc 0.8565 \n",
      "epoch : 61\n",
      "training loss: 0.0045, acc 0.8814 \n",
      "validation loss: 0.0058, validation acc 0.8580 \n",
      "epoch : 62\n",
      "training loss: 0.0045, acc 0.8819 \n",
      "validation loss: 0.0061, validation acc 0.8570 \n",
      "epoch : 63\n",
      "training loss: 0.0044, acc 0.8820 \n",
      "validation loss: 0.0059, validation acc 0.8570 \n",
      "epoch : 64\n",
      "training loss: 0.0045, acc 0.8829 \n",
      "validation loss: 0.0060, validation acc 0.8525 \n",
      "epoch : 65\n",
      "training loss: 0.0045, acc 0.8830 \n",
      "validation loss: 0.0059, validation acc 0.8600 \n",
      "epoch : 66\n",
      "training loss: 0.0044, acc 0.8866 \n",
      "validation loss: 0.0060, validation acc 0.8555 \n",
      "epoch : 67\n",
      "training loss: 0.0043, acc 0.8863 \n",
      "validation loss: 0.0062, validation acc 0.8475 \n",
      "epoch : 68\n",
      "training loss: 0.0044, acc 0.8856 \n",
      "validation loss: 0.0060, validation acc 0.8515 \n",
      "epoch : 69\n",
      "training loss: 0.0043, acc 0.8851 \n",
      "validation loss: 0.0059, validation acc 0.8595 \n",
      "epoch : 70\n",
      "training loss: 0.0043, acc 0.8866 \n",
      "validation loss: 0.0060, validation acc 0.8595 \n",
      "epoch : 71\n",
      "training loss: 0.0043, acc 0.8875 \n",
      "validation loss: 0.0060, validation acc 0.8545 \n",
      "epoch : 72\n",
      "training loss: 0.0043, acc 0.8890 \n",
      "validation loss: 0.0060, validation acc 0.8565 \n",
      "epoch : 73\n",
      "training loss: 0.0043, acc 0.8906 \n",
      "validation loss: 0.0063, validation acc 0.8485 \n",
      "epoch : 74\n",
      "training loss: 0.0043, acc 0.8865 \n",
      "validation loss: 0.0062, validation acc 0.8465 \n",
      "epoch : 75\n",
      "training loss: 0.0043, acc 0.8899 \n",
      "validation loss: 0.0062, validation acc 0.8525 \n",
      "epoch : 76\n",
      "training loss: 0.0042, acc 0.8906 \n",
      "validation loss: 0.0063, validation acc 0.8560 \n",
      "epoch : 77\n",
      "training loss: 0.0042, acc 0.8874 \n",
      "validation loss: 0.0060, validation acc 0.8600 \n",
      "epoch : 78\n",
      "training loss: 0.0042, acc 0.8885 \n",
      "validation loss: 0.0061, validation acc 0.8525 \n",
      "epoch : 79\n",
      "training loss: 0.0042, acc 0.8859 \n",
      "validation loss: 0.0062, validation acc 0.8480 \n",
      "epoch : 80\n",
      "training loss: 0.0042, acc 0.8885 \n",
      "validation loss: 0.0062, validation acc 0.8465 \n",
      "epoch : 81\n",
      "training loss: 0.0042, acc 0.8888 \n",
      "validation loss: 0.0062, validation acc 0.8525 \n",
      "epoch : 82\n",
      "training loss: 0.0042, acc 0.8907 \n",
      "validation loss: 0.0059, validation acc 0.8535 \n",
      "epoch : 83\n",
      "training loss: 0.0041, acc 0.8885 \n",
      "validation loss: 0.0064, validation acc 0.8570 \n",
      "epoch : 84\n",
      "training loss: 0.0041, acc 0.8921 \n",
      "validation loss: 0.0061, validation acc 0.8520 \n",
      "epoch : 85\n",
      "training loss: 0.0041, acc 0.8931 \n",
      "validation loss: 0.0064, validation acc 0.8510 \n",
      "epoch : 86\n",
      "training loss: 0.0041, acc 0.8920 \n",
      "validation loss: 0.0064, validation acc 0.8495 \n",
      "epoch : 87\n",
      "training loss: 0.0041, acc 0.8888 \n",
      "validation loss: 0.0064, validation acc 0.8495 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 88\n",
      "training loss: 0.0041, acc 0.8923 \n",
      "validation loss: 0.0063, validation acc 0.8520 \n",
      "epoch : 89\n",
      "training loss: 0.0041, acc 0.8960 \n",
      "validation loss: 0.0069, validation acc 0.8445 \n",
      "epoch : 90\n",
      "training loss: 0.0041, acc 0.8907 \n",
      "validation loss: 0.0062, validation acc 0.8505 \n",
      "epoch : 91\n",
      "training loss: 0.0041, acc 0.8917 \n",
      "validation loss: 0.0064, validation acc 0.8515 \n",
      "epoch : 92\n",
      "training loss: 0.0041, acc 0.8916 \n",
      "validation loss: 0.0064, validation acc 0.8470 \n",
      "epoch : 93\n",
      "training loss: 0.0040, acc 0.8925 \n",
      "validation loss: 0.0063, validation acc 0.8525 \n",
      "epoch : 94\n",
      "training loss: 0.0040, acc 0.8915 \n",
      "validation loss: 0.0064, validation acc 0.8500 \n",
      "epoch : 95\n",
      "training loss: 0.0040, acc 0.8946 \n",
      "validation loss: 0.0064, validation acc 0.8515 \n",
      "epoch : 96\n",
      "training loss: 0.0040, acc 0.8961 \n",
      "validation loss: 0.0066, validation acc 0.8455 \n",
      "epoch : 97\n",
      "training loss: 0.0040, acc 0.8959 \n",
      "validation loss: 0.0064, validation acc 0.8555 \n",
      "epoch : 98\n",
      "training loss: 0.0039, acc 0.8967 \n",
      "validation loss: 0.0065, validation acc 0.8435 \n",
      "epoch : 99\n",
      "training loss: 0.0039, acc 0.8966 \n",
      "validation loss: 0.0064, validation acc 0.8465 \n",
      "epoch : 100\n",
      "training loss: 0.0040, acc 0.8982 \n",
      "validation loss: 0.0065, validation acc 0.8465 \n",
      "epoch : 101\n",
      "training loss: 0.0039, acc 0.8971 \n",
      "validation loss: 0.0064, validation acc 0.8480 \n",
      "epoch : 102\n",
      "training loss: 0.0039, acc 0.8972 \n",
      "validation loss: 0.0065, validation acc 0.8335 \n",
      "epoch : 103\n",
      "training loss: 0.0039, acc 0.8966 \n",
      "validation loss: 0.0069, validation acc 0.8525 \n",
      "epoch : 104\n",
      "training loss: 0.0039, acc 0.8969 \n",
      "validation loss: 0.0070, validation acc 0.8445 \n",
      "epoch : 105\n",
      "training loss: 0.0040, acc 0.8949 \n",
      "validation loss: 0.0063, validation acc 0.8470 \n",
      "epoch : 106\n",
      "training loss: 0.0039, acc 0.9007 \n",
      "validation loss: 0.0063, validation acc 0.8480 \n",
      "epoch : 107\n",
      "training loss: 0.0039, acc 0.8963 \n",
      "validation loss: 0.0064, validation acc 0.8520 \n",
      "epoch : 108\n",
      "training loss: 0.0039, acc 0.8996 \n",
      "validation loss: 0.0067, validation acc 0.8455 \n",
      "epoch : 109\n",
      "training loss: 0.0038, acc 0.8992 \n",
      "validation loss: 0.0070, validation acc 0.8415 \n",
      "epoch : 110\n",
      "training loss: 0.0039, acc 0.8990 \n",
      "validation loss: 0.0067, validation acc 0.8460 \n",
      "epoch : 111\n",
      "training loss: 0.0038, acc 0.9015 \n",
      "validation loss: 0.0067, validation acc 0.8505 \n",
      "epoch : 112\n",
      "training loss: 0.0038, acc 0.8991 \n",
      "validation loss: 0.0065, validation acc 0.8460 \n",
      "epoch : 113\n",
      "training loss: 0.0039, acc 0.8988 \n",
      "validation loss: 0.0066, validation acc 0.8455 \n",
      "epoch : 114\n",
      "training loss: 0.0038, acc 0.9011 \n",
      "validation loss: 0.0068, validation acc 0.8420 \n",
      "epoch : 115\n",
      "training loss: 0.0038, acc 0.9043 \n",
      "validation loss: 0.0069, validation acc 0.8380 \n",
      "epoch : 116\n",
      "training loss: 0.0038, acc 0.9022 \n",
      "validation loss: 0.0070, validation acc 0.8410 \n",
      "epoch : 117\n",
      "training loss: 0.0038, acc 0.9001 \n",
      "validation loss: 0.0065, validation acc 0.8470 \n",
      "epoch : 118\n",
      "training loss: 0.0038, acc 0.8980 \n",
      "validation loss: 0.0069, validation acc 0.8490 \n",
      "epoch : 119\n",
      "training loss: 0.0038, acc 0.9031 \n",
      "validation loss: 0.0071, validation acc 0.8490 \n",
      "epoch : 120\n",
      "training loss: 0.0038, acc 0.9011 \n",
      "validation loss: 0.0067, validation acc 0.8515 \n",
      "epoch : 121\n",
      "training loss: 0.0038, acc 0.9014 \n",
      "validation loss: 0.0069, validation acc 0.8430 \n",
      "epoch : 122\n",
      "training loss: 0.0038, acc 0.9006 \n",
      "validation loss: 0.0072, validation acc 0.8390 \n",
      "epoch : 123\n",
      "training loss: 0.0038, acc 0.9016 \n",
      "validation loss: 0.0066, validation acc 0.8465 \n",
      "epoch : 124\n",
      "training loss: 0.0038, acc 0.9034 \n",
      "validation loss: 0.0065, validation acc 0.8370 \n",
      "epoch : 125\n",
      "training loss: 0.0037, acc 0.9019 \n",
      "validation loss: 0.0068, validation acc 0.8400 \n",
      "epoch : 126\n",
      "training loss: 0.0037, acc 0.9050 \n",
      "validation loss: 0.0068, validation acc 0.8510 \n",
      "epoch : 127\n",
      "training loss: 0.0037, acc 0.9039 \n",
      "validation loss: 0.0070, validation acc 0.8430 \n",
      "epoch : 128\n",
      "training loss: 0.0037, acc 0.9014 \n",
      "validation loss: 0.0069, validation acc 0.8400 \n",
      "epoch : 129\n",
      "training loss: 0.0037, acc 0.9066 \n",
      "validation loss: 0.0069, validation acc 0.8430 \n",
      "epoch : 130\n",
      "training loss: 0.0037, acc 0.9053 \n",
      "validation loss: 0.0074, validation acc 0.8390 \n",
      "epoch : 131\n",
      "training loss: 0.0037, acc 0.9019 \n",
      "validation loss: 0.0065, validation acc 0.8500 \n",
      "epoch : 132\n",
      "training loss: 0.0037, acc 0.9049 \n",
      "validation loss: 0.0069, validation acc 0.8505 \n",
      "epoch : 133\n",
      "training loss: 0.0036, acc 0.9050 \n",
      "validation loss: 0.0069, validation acc 0.8430 \n",
      "epoch : 134\n",
      "training loss: 0.0037, acc 0.9049 \n",
      "validation loss: 0.0069, validation acc 0.8465 \n",
      "epoch : 135\n",
      "training loss: 0.0036, acc 0.9041 \n",
      "validation loss: 0.0068, validation acc 0.8520 \n",
      "epoch : 136\n",
      "training loss: 0.0036, acc 0.9030 \n",
      "validation loss: 0.0069, validation acc 0.8380 \n",
      "epoch : 137\n",
      "training loss: 0.0037, acc 0.9032 \n",
      "validation loss: 0.0070, validation acc 0.8420 \n",
      "epoch : 138\n",
      "training loss: 0.0036, acc 0.9057 \n",
      "validation loss: 0.0069, validation acc 0.8505 \n",
      "epoch : 139\n",
      "training loss: 0.0036, acc 0.9053 \n",
      "validation loss: 0.0070, validation acc 0.8460 \n",
      "epoch : 140\n",
      "training loss: 0.0036, acc 0.9078 \n",
      "validation loss: 0.0069, validation acc 0.8335 \n",
      "epoch : 141\n",
      "training loss: 0.0037, acc 0.9036 \n",
      "validation loss: 0.0074, validation acc 0.8345 \n",
      "epoch : 142\n",
      "training loss: 0.0036, acc 0.9054 \n",
      "validation loss: 0.0073, validation acc 0.8370 \n",
      "epoch : 143\n",
      "training loss: 0.0037, acc 0.9057 \n",
      "validation loss: 0.0071, validation acc 0.8475 \n",
      "epoch : 144\n",
      "training loss: 0.0036, acc 0.9051 \n",
      "validation loss: 0.0070, validation acc 0.8465 \n",
      "epoch : 145\n",
      "training loss: 0.0036, acc 0.9065 \n",
      "validation loss: 0.0068, validation acc 0.8385 \n",
      "epoch : 146\n",
      "training loss: 0.0035, acc 0.9099 \n",
      "validation loss: 0.0075, validation acc 0.8405 \n",
      "epoch : 147\n",
      "training loss: 0.0035, acc 0.9081 \n",
      "validation loss: 0.0073, validation acc 0.8380 \n",
      "epoch : 148\n",
      "training loss: 0.0036, acc 0.9060 \n",
      "validation loss: 0.0073, validation acc 0.8360 \n",
      "epoch : 149\n",
      "training loss: 0.0035, acc 0.9103 \n",
      "validation loss: 0.0072, validation acc 0.8405 \n",
      "epoch : 150\n",
      "training loss: 0.0035, acc 0.9061 \n",
      "validation loss: 0.0074, validation acc 0.8280 \n",
      "epoch : 151\n",
      "training loss: 0.0035, acc 0.9049 \n",
      "validation loss: 0.0076, validation acc 0.8230 \n",
      "epoch : 152\n",
      "training loss: 0.0035, acc 0.9085 \n",
      "validation loss: 0.0073, validation acc 0.8425 \n",
      "epoch : 153\n",
      "training loss: 0.0035, acc 0.9059 \n",
      "validation loss: 0.0081, validation acc 0.8320 \n",
      "epoch : 154\n",
      "training loss: 0.0036, acc 0.9061 \n",
      "validation loss: 0.0071, validation acc 0.8370 \n",
      "epoch : 155\n",
      "training loss: 0.0035, acc 0.9080 \n",
      "validation loss: 0.0073, validation acc 0.8340 \n",
      "epoch : 156\n",
      "training loss: 0.0035, acc 0.9106 \n",
      "validation loss: 0.0080, validation acc 0.8345 \n",
      "epoch : 157\n",
      "training loss: 0.0035, acc 0.9090 \n",
      "validation loss: 0.0072, validation acc 0.8340 \n",
      "epoch : 158\n",
      "training loss: 0.0035, acc 0.9100 \n",
      "validation loss: 0.0076, validation acc 0.8430 \n",
      "epoch : 159\n",
      "training loss: 0.0035, acc 0.9078 \n",
      "validation loss: 0.0079, validation acc 0.8285 \n",
      "epoch : 160\n",
      "training loss: 0.0035, acc 0.9091 \n",
      "validation loss: 0.0077, validation acc 0.8330 \n",
      "epoch : 161\n",
      "training loss: 0.0035, acc 0.9103 \n",
      "validation loss: 0.0071, validation acc 0.8430 \n",
      "epoch : 162\n",
      "training loss: 0.0035, acc 0.9103 \n",
      "validation loss: 0.0078, validation acc 0.8255 \n",
      "epoch : 163\n",
      "training loss: 0.0034, acc 0.9099 \n",
      "validation loss: 0.0076, validation acc 0.8385 \n",
      "epoch : 164\n",
      "training loss: 0.0035, acc 0.9082 \n",
      "validation loss: 0.0070, validation acc 0.8300 \n",
      "epoch : 165\n",
      "training loss: 0.0035, acc 0.9110 \n",
      "validation loss: 0.0073, validation acc 0.8320 \n",
      "epoch : 166\n",
      "training loss: 0.0034, acc 0.9111 \n",
      "validation loss: 0.0077, validation acc 0.8375 \n",
      "epoch : 167\n",
      "training loss: 0.0034, acc 0.9099 \n",
      "validation loss: 0.0078, validation acc 0.8420 \n",
      "epoch : 168\n",
      "training loss: 0.0033, acc 0.9131 \n",
      "validation loss: 0.0079, validation acc 0.8415 \n",
      "epoch : 169\n",
      "training loss: 0.0034, acc 0.9133 \n",
      "validation loss: 0.0075, validation acc 0.8460 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-ba6473bcd6fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mval_running_corrects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\neele\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\neele\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\neele\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\neele\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\neele\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\neele\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "running_loss_history = []\n",
    "epoch_list = []\n",
    "running_corrects_history = []\n",
    "val_running_loss_history = []\n",
    "val_running_corrects_history = []\n",
    "\n",
    "print(\"Starting with the training...\")\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "\n",
    "        inputs = Variable(inputs).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        output = model(inputs)\n",
    "        \n",
    "        loss = criterion(output, labels.unsqueeze(1).float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        preds = torch.round(output).to(int).squeeze(1)\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in test_loader:\n",
    "                val_inputs = Variable(val_inputs).to(device)\n",
    "                val_labels = Variable(val_labels).to(device)\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs, val_labels.unsqueeze(1).float())\n",
    "                \n",
    "                val_preds = torch.round(val_outputs).to(int).squeeze(1)\n",
    "                val_running_loss += val_loss.item()\n",
    "                val_running_corrects += torch.sum(val_preds == val_labels.data)\n",
    "    \n",
    "    epoch_loss = running_loss/len(train_loader.dataset)\n",
    "    epoch_acc = running_corrects.float()/ len(train_loader.dataset)\n",
    "    running_loss_history.append(epoch_loss)\n",
    "    running_corrects_history.append(epoch_acc)\n",
    "    \n",
    "    val_epoch_loss = val_running_loss/len(test_loader.dataset)\n",
    "    val_epoch_acc = val_running_corrects.float()/ len(test_loader.dataset)\n",
    "    val_running_loss_history.append(val_epoch_loss)\n",
    "    val_running_corrects_history.append(val_epoch_acc)\n",
    "    print('epoch :', (e+1))\n",
    "    print('training loss: {:.4f}, acc {:.4f} '.format(epoch_loss, epoch_acc.item()))\n",
    "    print('validation loss: {:.4f}, validation acc {:.4f} '.format(val_epoch_loss, val_epoch_acc.item()))\n",
    "\n",
    "    epoch_list.append(e + 1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list,running_loss_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.title(\"Accuracy vs Number of Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Predicted Values')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions=[]\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(X_test):\n",
    "        y_pred=model(data)\n",
    "        y_pred_new = 0 if y_pred <= 0.5 else 1\n",
    "        predictions.append(y_pred_new)\n",
    "        \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test.to('cpu'),predictions)\n",
    "cm\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8345"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_test.to('cpu'),predictions)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
